{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebd8e60",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #87CEEB; border-radius: 12px; padding: 20px; border: 3px solid #87CEEB;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">MODELOS DE PREDICCIÓN:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a877e38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34634\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\34634\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: session_info in c:\\users\\34634\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: stdlib-list in c:\\users\\34634\\anaconda3\\lib\\site-packages (from session_info) (0.10.0)\n",
      "WARNING:tensorflow:From C:\\Users\\34634\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias para el correcto funcionamiento de todos lo modelos y demás operaciones con los datos\n",
    "import importlib\n",
    "import joblib\n",
    "import subprocess\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "!pip install session_info\n",
    "\n",
    "import session_info\n",
    "\n",
    "#Froms\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from packaging import version\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222cef29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Time</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022484408</td>\n",
       "      <td>2016-04-12 07:21:00</td>\n",
       "      <td>101.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.32064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022484408</td>\n",
       "      <td>2016-04-12 07:22:00</td>\n",
       "      <td>87.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022484408</td>\n",
       "      <td>2016-04-12 07:23:00</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.34901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022484408</td>\n",
       "      <td>2016-04-12 07:24:00</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.03770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022484408</td>\n",
       "      <td>2016-04-12 07:25:00</td>\n",
       "      <td>56.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>1.03770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333141</th>\n",
       "      <td>8877689391</td>\n",
       "      <td>2016-05-12 13:55:00</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1.33353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333142</th>\n",
       "      <td>8877689391</td>\n",
       "      <td>2016-05-12 13:56:00</td>\n",
       "      <td>61.875000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.33353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333143</th>\n",
       "      <td>8877689391</td>\n",
       "      <td>2016-05-12 13:57:00</td>\n",
       "      <td>58.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>1.33353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333144</th>\n",
       "      <td>8877689391</td>\n",
       "      <td>2016-05-12 13:58:00</td>\n",
       "      <td>61.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.33353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333145</th>\n",
       "      <td>8877689391</td>\n",
       "      <td>2016-05-12 13:59:00</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.33353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333146 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id                 Time   HeartRate  Intensity  Calories\n",
       "0       2022484408  2016-04-12 07:21:00  101.600000          1   3.32064\n",
       "1       2022484408  2016-04-12 07:22:00   87.888889          1   3.94326\n",
       "2       2022484408  2016-04-12 07:23:00   58.000000          0   1.34901\n",
       "3       2022484408  2016-04-12 07:24:00   58.000000          0   1.03770\n",
       "4       2022484408  2016-04-12 07:25:00   56.777778          0   1.03770\n",
       "...            ...                  ...         ...        ...       ...\n",
       "333141  8877689391  2016-05-12 13:55:00   60.666667          0   1.33353\n",
       "333142  8877689391  2016-05-12 13:56:00   61.875000          0   1.33353\n",
       "333143  8877689391  2016-05-12 13:57:00   58.142857          0   1.33353\n",
       "333144  8877689391  2016-05-12 13:58:00   61.200000          0   1.33353\n",
       "333145  8877689391  2016-05-12 13:59:00   58.000000          0   1.33353\n",
       "\n",
       "[333146 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_csv(\"../Fitabase Data 4.12.16-5.12.16/test_train_data.csv\")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae1ffd3",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: #87CEEB; border-radius: 12px; padding: 20px; border: 3px solid #87CEEB;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\"> Instalación/Actualización de librerías necesarias:📦</strong>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8199d93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost ya está instalado en el sistema.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    importlib.import_module('xgboost')\n",
    "    print(\"XGBoost ya está instalado en el sistema.\")\n",
    "except ImportError:\n",
    "    subprocess.run(['pip', 'install', 'xgboost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7106e1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM ya está instalado en el sistema.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    importlib.import_module('lightgbm')\n",
    "    print(\"LightGBM ya está instalado en el sistema.\")\n",
    "except ImportError:\n",
    "    subprocess.run(['pip', 'install', 'lightgbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e97fb1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow ya está instalado en el sistema.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    importlib.import_module('tensorflow')\n",
    "    print(\"TensorFlow ya está instalado en el sistema.\")\n",
    "except ImportError:\n",
    "    subprocess.run(['pip', 'install', 'tensorflow', 'scikit-learn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e619aa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pip', 'install', '--upgrade', 'lightgbm', 'pandas', 'dask'], returncode=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['pip', 'install', '--upgrade', 'lightgbm', 'pandas', 'dask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebdc0631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyArrow versión 15.0.0 ya está instalada.\n"
     ]
    }
   ],
   "source": [
    "required_version = '14.0.1'\n",
    "\n",
    "try:\n",
    "    pyarrow_version = importlib.import_module('pyarrow').__version__\n",
    "    if version.parse(pyarrow_version) < version.parse(required_version):\n",
    "        print(f\"PyArrow versión {pyarrow_version} encontrada. Actualizando a la versión {required_version}.\")\n",
    "        subprocess.run(['pip', 'install', f'pyarrow>={required_version}'])\n",
    "    else:\n",
    "        print(f\"PyArrow versión {pyarrow_version} ya está instalada.\")\n",
    "except ImportError:\n",
    "    subprocess.run(['pip', 'install', f'pyarrow>={required_version}'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b0a6a6",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #8990EB; border-radius: 12px; padding: 20px; border: 3px solid #8990EB;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">⚠ **User Alert:**</strong> Don't forget to RESTART the kernel  <strong style=\"color: #000000; font-size: 1em;\">(if libraries were not installed in current PC)</strong> for the magic to happen after ADOPTING the new libraries.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99672c8c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #87CEEB; border-radius: 12px; padding: 20px; border: 3px solid #87CEEB;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">Información de sesión:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15af5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "joblib              1.3.2\n",
      "keras               2.15.0\n",
      "lightgbm            4.4.0\n",
      "numpy               1.24.4\n",
      "packaging           21.3\n",
      "pandas              2.2.2\n",
      "session_info        1.0.0\n",
      "sklearn             1.0.2\n",
      "xgboost             2.0.3\n",
      "-----\n",
      "IPython             8.18.1\n",
      "jupyter_client      7.3.4\n",
      "jupyter_core        4.11.1\n",
      "jupyterlab          3.4.4\n",
      "notebook            6.4.12\n",
      "-----\n",
      "Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "Windows-10-10.0.22000-SP0\n",
      "-----\n",
      "Session information updated at 2024-07-18 09:23\n"
     ]
    }
   ],
   "source": [
    "session_info.show(html=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b1456",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #90EE90; border-radius: 12px; padding: 20px; border: 3px solid #90EE90;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">Preprocesamiento de los datos:🔧</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5aa142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Time'] = pd.to_datetime(result_df['Time'])\n",
    "\n",
    "result_df['Hour'] = result_df['Time'].dt.hour\n",
    "result_df['Minutes'] = result_df['Time'].dt.minute\n",
    "result_df['Weekday'] = result_df['Time'].dt.weekday\n",
    "\n",
    "features = ['Id', 'Hour', 'Minutes', 'Intensity', 'Calories']\n",
    "target = 'HeartRate'\n",
    "\n",
    "X = result_df[features]\n",
    "y = result_df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.17, random_state=777)\n",
    "\n",
    "categorical_features = ['Id']\n",
    "numeric_features = ['Hour', 'Minutes', 'Intensity', 'Calories']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da6809",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D8BFD9; border-radius: 12px; padding: 20px; border: 3px solid #D8BFD8;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">Linear Regression</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "082fe502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94;1mR2 score: 0.7415176189275107\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\033[94;1mR2 score: {r2}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f5f0c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D8BFD9; border-radius: 12px; padding: 20px; border: 3px solid #D8BFD8;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">Gradient Boosted Trees : XGBoost🌳</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81d7a525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94;1mPromedio R2 Score (XGBoost): 0.858344518126301\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "num_splits = 5 \n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "xgb_scores = cross_val_score(xgb_model, X, y, scoring='r2', cv=KFold(n_splits=num_splits, shuffle=True, random_state=42))\n",
    "\n",
    "print(f\"\\033[94;1mPromedio R2 Score (XGBoost): {xgb_scores.mean()}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c58919e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94;1mPromedio R2 Score (XGBoost) con mejores hiperparámetros: 0.8604436463886229\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_params = {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
    "\n",
    "# Crear el modelo XGBoost con los mejores hiperparámetros\n",
    "optimal_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    subsample=best_params['subsample'],\n",
    "    colsample_bytree=best_params['colsample_bytree']\n",
    ")\n",
    "\n",
    "num_splits = 5\n",
    "xgb_scores = cross_val_score(optimal_model, X, y, scoring='r2', cv=KFold(n_splits=num_splits, shuffle=True, random_state=42))\n",
    "print(f\"\\033[94;1mPromedio R2 Score (XGBoost) con mejores hiperparámetros: {xgb_scores.mean()}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70565d5e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D8BFD8; border-radius: 12px; padding: 20px; border: 3px solid #D8BFD8;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">LightGBM:🌳</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc036201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34634\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:150: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] El sistema no puede encontrar el archivo especificado\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\34634\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 227, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"C:\\Users\\34634\\anaconda3\\lib\\subprocess.py\", line 505, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"C:\\Users\\34634\\anaconda3\\lib\\subprocess.py\", line 951, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\34634\\anaconda3\\lib\\subprocess.py\", line 1420, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 358\n",
      "[LightGBM] [Info] Number of data points in the train set: 266516, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 73.702794\n",
      "[LightGBM] [Info] Total Bins 358\n",
      "[LightGBM] [Info] Number of data points in the train set: 266517, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 73.701315\n",
      "[LightGBM] [Info] Total Bins 358\n",
      "[LightGBM] [Info] Number of data points in the train set: 266517, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 73.703051\n",
      "[LightGBM] [Info] Total Bins 358\n",
      "[LightGBM] [Info] Number of data points in the train set: 266517, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 73.734438\n",
      "[LightGBM] [Info] Total Bins 358\n",
      "[LightGBM] [Info] Number of data points in the train set: 266517, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 73.707150\n",
      "\u001b[94;1mPromedio R2 Score (LightGBM): 0.8608125059372875\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_params = {'learning_rate': 0.2, 'n_estimators': 200, 'num_leaves': 40}\n",
    "best_model = lgb.LGBMRegressor(objective='regression', random_state=42, force_row_wise=True, **best_params)\n",
    "\n",
    "num_splits = 5 \n",
    "lgb_scores = cross_val_score(best_model, X, y, scoring='r2', cv=KFold(n_splits=num_splits, shuffle=True, random_state=42))\n",
    "\n",
    "print(f\"\\033[94;1mPromedio R2 Score (LightGBM): {lgb_scores.mean()}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75e6a767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../ML models/LightGBM_ML.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, '../ML models/LightGBM_ML.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cc66721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 374\n",
      "[LightGBM] [Info] Number of data points in the train set: 266516, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 73.702794\n",
      "[LightGBM] [Info] Total Bins 374\n",
      "[LightGBM] [Info] Number of data points in the train set: 266517, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 73.701315\n",
      "[LightGBM] [Info] Total Bins 374\n",
      "[LightGBM] [Info] Number of data points in the train set: 266517, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 73.703051\n",
      "[LightGBM] [Info] Total Bins 374\n",
      "[LightGBM] [Info] Number of data points in the train set: 266517, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 73.734438\n",
      "[LightGBM] [Info] Total Bins 374\n",
      "[LightGBM] [Info] Number of data points in the train set: 266517, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 73.707150\n",
      "\u001b[94;1mPromedio R2 Score (LightGBM): 0.8555762087754732\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Mejores hiperparámetros encontrados previamente con GridSearch\n",
    "best_params = {'learning_rate': 0.2, 'n_estimators': 200, 'num_leaves': 40}\n",
    "\n",
    "best_model = lgb.LGBMRegressor(objective='regression', random_state=42, **best_params)\n",
    "\n",
    "num_splits = 5 \n",
    "lgb_params = best_params.copy()\n",
    "lgb_params['force_row_wise'] = True\n",
    "\n",
    "best_model_force_row_wise = lgb.LGBMRegressor(objective='regression', random_state=42, **lgb_params)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('regressor', best_model_force_row_wise)])\n",
    "lgb_scores = cross_val_score(pipeline, X, y, scoring='r2', cv=KFold(n_splits=num_splits, shuffle=True, random_state=42))\n",
    "\n",
    "print(f\"\\033[94;1mPromedio R2 Score (LightGBM): {lgb_scores.mean()}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f18cb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D8BFD8; border-radius: 12px; padding: 20px; border: 3px solid #D8BFD8;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">LSTM: Long Short Term Memory</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d5c48e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\34634\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\34634\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From C:\\Users\\34634\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "8641/8641 [==============================] - 25s 3ms/step - loss: 389.5086\n",
      "Epoch 2/15\n",
      "8641/8641 [==============================] - 24s 3ms/step - loss: 119.9024\n",
      "Epoch 3/15\n",
      "8641/8641 [==============================] - 25s 3ms/step - loss: 118.6448\n",
      "Epoch 4/15\n",
      "8641/8641 [==============================] - 26s 3ms/step - loss: 117.6529\n",
      "Epoch 5/15\n",
      "8641/8641 [==============================] - 25s 3ms/step - loss: 116.6633\n",
      "Epoch 6/15\n",
      "8641/8641 [==============================] - 26s 3ms/step - loss: 115.6028\n",
      "Epoch 7/15\n",
      "8641/8641 [==============================] - 28s 3ms/step - loss: 114.7307\n",
      "Epoch 8/15\n",
      "8641/8641 [==============================] - 29s 3ms/step - loss: 114.0143\n",
      "Epoch 9/15\n",
      "8641/8641 [==============================] - 26s 3ms/step - loss: 113.6048\n",
      "Epoch 10/15\n",
      "8641/8641 [==============================] - 26s 3ms/step - loss: 113.2977\n",
      "Epoch 11/15\n",
      "8641/8641 [==============================] - 25s 3ms/step - loss: 113.1068\n",
      "Epoch 12/15\n",
      "8641/8641 [==============================] - 25s 3ms/step - loss: 112.9239\n",
      "Epoch 13/15\n",
      "8641/8641 [==============================] - 29s 3ms/step - loss: 112.7350\n",
      "Epoch 14/15\n",
      "8641/8641 [==============================] - 26s 3ms/step - loss: 112.6043\n",
      "Epoch 15/15\n",
      "8641/8641 [==============================] - 27s 3ms/step - loss: 112.4409\n",
      "1770/1770 [==============================] - 3s 2ms/step\n",
      "\u001b[94;1mR2 Score: 0.592538\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(120, activation='relu', input_shape=(1, len(numeric_features))))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "model.fit(X_train_reshaped, y_train, epochs=15, batch_size=32, verbose=1)\n",
    "\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\033[94;1mR2 Score: {r2:.6f}\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f17156",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D8BFD8; border-radius: 12px; padding: 20px; border: 3px solid #D8BFD8;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">MLPRegressor: Multi-Layer Perceptron Regressor</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba1b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Scores (MLPRegressor) en 5-fold cross-validation: [0.85287847 0.84818361 0.84978637 0.84772851 0.85042114]\n",
      "\u001b[94;1mPromedio R2 Score (MLPRegressor): 0.8497996193926494\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('regressor', MLPRegressor(random_state=42, max_iter=1300))])\n",
    "num_splits = 5  \n",
    "\n",
    "# Validación cruzada \n",
    "mlp_scores = cross_val_score(pipeline, X, y, scoring='r2', cv=KFold(n_splits=num_splits, shuffle=True, random_state=42))\n",
    "\n",
    "print(f\"R2 Scores (MLPRegressor) en {num_splits}-fold cross-validation: {mlp_scores}\")\n",
    "print(f\"\\033[94;1mPromedio R2 Score (MLPRegressor): {mlp_scores.mean()}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0839ae",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D8BFD8; border-radius: 12px; padding: 20px; border: 3px solid #D8BFD8;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">KNN Regressor:📍</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0744e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94;1mPPromedio R2 Score (KNeighborsRegressor): 0.8261730442623068\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "numeric_features = ['Hour', 'Minutes', 'Intensity', 'Calories']\n",
    "categorical_features = ['Id']\n",
    "\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "num_splits = 5\n",
    "knn_scores = cross_val_score(pipeline, X, y, scoring='r2', cv=KFold(n_splits=num_splits, shuffle=True, random_state=42))\n",
    "\n",
    "print(f\"\\033[94;1mPPromedio R2 Score (KNeighborsRegressor): {knn_scores.mean()}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f424c3",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D8BFD8; border-radius: 12px; padding: 20px; border: 3px solid #D8BFD8;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">Decision Tree Regressor:🌳</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50bff77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 60.792109505792425\n",
      "Mean MSE across 5-fold Cross-Validation: 62.69339791385077\n",
      "\u001b[94;1mMSE Scores for each fold: [62.22259701 62.84575426 63.5455043  62.57267111 62.28046288]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dt_regressor = DecisionTreeRegressor(random_state=11101)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', dt_regressor)\n",
    "])\n",
    "\n",
    "num_splits = 5\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=num_splits, scoring='neg_mean_squared_error')\n",
    "mse_scores = -scores \n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error on Test Set: {mse_test}')\n",
    "\n",
    "\n",
    "print(f'Mean MSE across {num_splits}-fold Cross-Validation: {mse_scores.mean()}')\n",
    "print(f'\\033[94;1mMSE Scores for each fold: {mse_scores}\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e00256",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D8BFD8; border-radius: 12px; padding: 20px; border: 3px solid #D8BFD8;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">SVM: Support Vector Machine Regressor:🤖</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e586639",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(kernel='rbf', gamma='auto', epsilon=0.1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(\"R2 score on the test set:\", score)\n",
    "\n",
    "# Cross-validation\n",
    "num_splits = 5\n",
    "svm_scores = cross_val_score(model, X, y, scoring='r2', cv=KFold(n_splits=num_splits, shuffle=True, random_state=11101))\n",
    "\n",
    "print(f\"R2 Scores (SVR) in {num_splits}-fold cross-validation: {svm_scores}\")\n",
    "print(f\"\\033[94;1mAverage R2 Score (SVR) across {num_splits}-fold cross-validation: {svm_scores.mean()}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc773a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D8BFD8; border-radius: 12px; padding: 20px; border: 3px solid #D8BFD8;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\">Random Forest Regressor:🌳</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=11101)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(f'R2 Score on Test Set: {score}')\n",
    "\n",
    "num_splits = 5\n",
    "rf_scores = cross_val_score(pipeline, X, y, scoring='r2', cv=KFold(n_splits=num_splits, shuffle=True, random_state=11101))\n",
    "\n",
    "print(f\"R2 Scores (Random Forest) in {num_splits}-fold cross-validation: {rf_scores}\")\n",
    "print(f\"\\033[94;1mAverage R2 Score (Random Forest) across {num_splits}-fold cross-validation: {rf_scores.mean()}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06492148",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D8BFD8; border-radius: 12px; padding: 20px; border: 3px solid #D8BFD8;\">\n",
    "    <strong style=\"color: #000000; font-size: 1.5em;\"> Modelo Combinado: LightGBM, RandomForest, XGBoost</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa098cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 358\n",
      "[LightGBM] [Info] Number of data points in the train set: 276511, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 73.705764\n",
      "\u001b[94;1mR2 score del modelo combinado en el conjunto de prueba: 0.8641493240621558\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_params = {'learning_rate': 0.2, 'n_estimators': 200, 'num_leaves': 31, 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
    "\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    subsample=best_params['subsample'],\n",
    "    colsample_bytree=best_params['colsample_bytree']\n",
    ")\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    random_state=42,\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    num_leaves=best_params['num_leaves']\n",
    ")\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "voting_regressor = VotingRegressor(\n",
    "    estimators=[('xgb', xgb_model), ('lgb', lgb_model), ('rf', rf_model)]\n",
    ")\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "\n",
    "score = voting_regressor.score(X_test, y_test)\n",
    "print(f\"\\033[94;1mR2 score del modelo combinado en el conjunto de prueba: {score}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6bbbcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ML models/L_XG_RF_ML.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(voting_regressor, '../ML models/L_XG_RF_ML.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
